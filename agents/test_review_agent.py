from crewai import Agent
from ollama_utils import appeler_ollama

test_review_agent = Agent(
    role="Critique IA des cas de test",
    goal="Relire les cas de test proposÃ©s et suggÃ©rer des amÃ©liorations utiles et exploitables.",
    backstory=(
        "Tu es un expert en validation logicielle. Tu relis les cas de test pour Ã©valuer leur qualitÃ©, dÃ©tecter des manques et proposer des cas plus pertinents ou extrÃªmes."
    ),
    verbose=True,
    allow_delegation=False
)

def run_test_case_review(signature: str, test_cases: str) -> str:
    prompt = f"""
Tu es un expert en validation logicielle. Voici une mÃ©thode C# :

Signature :
{signature}

Et les cas de test gÃ©nÃ©rÃ©s automatiquement :

{test_cases}

Ta mission :
1. Ã‰valuer la qualitÃ© des cas de test proposÃ©s : sont-ils pertinents, variÃ©s, suffisants ?
2. Identifier les cas absents ou mal choisis (ex : 0, null, max/min, Ã©galitÃ©s)
3. Expliquer briÃ¨vement les points forts et les manques
---

Ã‰valuation :
- [ta remarque sur les cas existants]

Recommandations :
- [liste d'idÃ©es ou corrections utiles]


Sois clair et utile.
"""
    return appeler_ollama(prompt)

def run_test_code_review(test_code: str) -> str:
    prompt = f"""
Tu es un expert en qualitÃ© logicielle et en tests unitaires C# avec NUnit 3.

Voici un fichier de tests gÃ©nÃ©rÃ© automatiquement :

{test_code}

Ta mission :
1. Ã‰valuer sa clartÃ©, sa cohÃ©rence, et la couverture des cas testÃ©s.
2. Indiquer les bonnes pratiques suivies ou manquantes.
3. Proposer des corrections ou suggestions dâ€™amÃ©lioration prÃ©cises.

Retourne ta rÃ©ponse dans ce format :

ğŸ“ Ã‰valuation :
- [tes remarques sur le fichier]

ğŸ“Œ Suggestions :
- [recommandations concrÃ¨tes pour amÃ©liorer le fichier]
"""
    return appeler_ollama(prompt)